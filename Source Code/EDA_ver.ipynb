{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "from collections import namedtuple\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Definitions\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# a label and all meta information\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "\n",
    "    'trainId'     , # An integer ID that overwrites the ID above, when creating ground truth\n",
    "                    # images for training.\n",
    "                    # For training, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# A list of all labels\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Please adapt the train IDs as appropriate for you approach.\n",
    "# Note that you might want to ignore labels with ID 255 during training.\n",
    "# Make sure to provide your results using the original IDs and not the training IDs.\n",
    "# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n",
    "\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'ground'          , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'ground'          , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      255 , 'ground'          , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      255 , 'ground'          , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , 34 ,       19 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]\n",
    "\n",
    "# function to get the label from the name\n",
    "def find_label(name):\n",
    "    for label in labels:\n",
    "        if label.name == name:\n",
    "            return label.trainId, label.color\n",
    "    return 255, (0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Working Within Kaggle - Seif\n",
    "#--------------------------------------------------------------------------------\n",
    "# train_images_folder = '/kaggle/input/cityscapes-segmentation/images/train'\n",
    "# train_labels_folder = '/kaggle/input/cityscapes-segmentation/labels/train'\n",
    "\n",
    "# training_csv_file_path = '/kaggle/working/cityscapes_training.csv'\n",
    "# val_csv_file_path = '/kaggle/working/cityscapes_val.csv'\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "#For Working Locally - Youssif\n",
    "#--------------------------------------------------------------------------------\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "train_images_folder = os.path.join(current_dir, 'DataSet\\\\Images\\\\Train_Set')\n",
    "train_labels_folder = os.path.join(current_dir, 'DataSet\\\\Labels\\\\train')\n",
    "\n",
    "training_csv_file_path = os.path.join(current_dir, 'DataSet\\\\cityscapes_training.csv')\n",
    "val_csv_file_path = os.path.join(current_dir, 'DataSet\\\\cityscapes_val.csv')\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "data = {\n",
    "    'image_path': [],\n",
    "    'label_mask_path': [],\n",
    "    'label_json_path': []\n",
    "}\n",
    "\n",
    "for city in os.listdir(train_images_folder):\n",
    "    city_image_folder = os.path.join(train_images_folder, city)\n",
    "    city_label_folder = os.path.join(train_labels_folder, city)\n",
    "    # print(f\"Processing {city} ...\")\n",
    "    \n",
    "    if os.path.isdir(city_image_folder):\n",
    "        for image_file in os.listdir(city_image_folder):\n",
    "            # print(f\"Processing {image_file} ...\")\n",
    "            if image_file.endswith('_leftImg8bit.png'):\n",
    "                image_name_base = image_file.replace('_leftImg8bit.png', '')\n",
    "                label_mask_file = f\"{image_name_base}_gtFine_labelTrainIds.png\"\n",
    "                label_json_file = f\"{image_name_base}_gtFine_polygons.json\"\n",
    "                \n",
    "                data['image_path'].append(os.path.join(city_image_folder, image_file))\n",
    "                data['label_mask_path'].append(os.path.join(city_label_folder, label_mask_file))\n",
    "                data['label_json_path'].append(os.path.join(city_label_folder, label_json_file))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=23, shuffle=True)\n",
    "\n",
    "train_df.to_csv(training_csv_file_path, index=False)\n",
    "val_df.to_csv(val_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Working Within Kaggle - Seif\n",
    "#--------------------------------------------------------------------------------\n",
    "# test_images_folder = '/kaggle/input/cityscapes-segmentation/images/test'\n",
    "\n",
    "# test_csv_file_path = '/kaggle/working/cityscapes_test.csv'\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "#For Working Locally - Youssif\n",
    "#--------------------------------------------------------------------------------\n",
    "test_images_folder = os.path.join(current_dir, 'DataSet\\\\Images\\\\Test_Set')\n",
    "\n",
    "test_csv_file_path = os.path.join(current_dir, 'DataSet\\\\cityscapes_test.csv')\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "test_data = {\n",
    "    'image_path': []\n",
    "}\n",
    "\n",
    "for city in os.listdir(test_images_folder):\n",
    "    city_image_folder = os.path.join(test_images_folder, city)\n",
    "    \n",
    "    if os.path.isdir(city_image_folder):\n",
    "        for image_file in os.listdir(city_image_folder):\n",
    "            if image_file.endswith('_leftImg8bit.png'):\n",
    "                test_data['image_path'].append(os.path.join(city_image_folder, image_file))\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "test_df.to_csv(test_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying A Sample of Images and Masks\n",
    "def show_img_mask(row):\n",
    "    image = cv2.cvtColor(cv2.imread(row['image_path']), cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(row['label_mask_path'])\n",
    "\n",
    "    json_data = json.load(open(row['label_json_path']))\n",
    "\n",
    "    for obj in json_data['objects']:\n",
    "        label = obj['label']\n",
    "        trainId, color = find_label(label)\n",
    "        if trainId != 255:\n",
    "            mask = cv2.fillPoly(mask, np.array([obj['polygon']], dtype=np.int32), color)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Image')\n",
    "    ax[1].imshow(mask, cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Mask')\n",
    "    plt.show()\n",
    "\n",
    "rSample = train_df.sample(5)\n",
    "for index, row in rSample.iterrows():\n",
    "    show_img_mask(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the Distribution of the Labels accross the train Dataset\n",
    "labels_freq = {label.name: 0 for label in labels}\n",
    "labels_not_found = {}\n",
    "\n",
    "dimensions_freq = {}\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    json_data = json.load(open(row['label_json_path']))\n",
    "    \n",
    "    dimensions = f\"{json_data['imgWidth']}x{json_data['imgHeight']}\"\n",
    "    dimensions_freq[dimensions] = dimensions_freq.get(dimensions, 0) + 1\n",
    "\n",
    "    for obj in json_data['objects']:\n",
    "        label = obj['label']\n",
    "        if label in labels_freq:\n",
    "            labels_freq[label] += 1\n",
    "        else:\n",
    "            if label not in labels_not_found:\n",
    "                labels_not_found[label] = 1\n",
    "            else:\n",
    "                labels_not_found[label] += 1\n",
    "        \n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(labels_freq.keys(), labels_freq.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "print(labels_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot for the Dimensions of the Images\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(dimensions_freq.keys(), dimensions_freq.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# All Images have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing & The rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class of Loading Data into Images and Masks\n",
    "class LoadData():\n",
    "    def __init__(self, keys):\n",
    "        self.keys = keys\n",
    "        self.key_size = len(keys)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if 'image_path' in self.keys and sample.get('image_path', None) is not None:\n",
    "            image = cv2.imread(sample['image_path']) \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "        else:\n",
    "            image = None\n",
    "\n",
    "        if self.key_size == 3:\n",
    "            mask_path = sample.get(\"label_mask_path\", None)\n",
    "            if mask_path:\n",
    "                mask = cv2.imread(mask_path)  \n",
    "            else:\n",
    "                mask = None\n",
    "            \n",
    "            json_path = sample.get(\"label_json_path\", None)\n",
    "            if json_path:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    json_data = json.load(f)\n",
    "\n",
    "                img_height = json_data[\"imgHeight\"]\n",
    "                img_width = json_data[\"imgWidth\"]\n",
    "                objects = json_data[\"objects\"]\n",
    "\n",
    "                for obj in objects:\n",
    "                    label = obj['label']\n",
    "                    polygon = np.array(obj['polygon'], dtype=np.int32)\n",
    "                    id_, color = find_label(label) \n",
    "                    # Skip ignored labels (trainId 255)\n",
    "                    if id_ != 255:\n",
    "                        cv2.fillPoly(mask, [polygon], color=color)\n",
    "            \n",
    "            return (image, mask)\n",
    "\n",
    "        return (image, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvToTensor():\n",
    "    def __call__(self, sample):\n",
    "        # Convert the image to a tensor and permute dimensions (HWC to CHW)\n",
    "        image_tensor = torch.tensor(sample[0].transpose(2, 0, 1), dtype=torch.float32, device=device) / 255.0 # normalize\n",
    "        if sample[1] is not None:\n",
    "            mask_tensor = torch.tensor(sample[1], dtype=torch.long, device=device)\n",
    "        else:\n",
    "            mask_tensor = None\n",
    "        return (image_tensor, mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : TRAIN DATA PREPROCESSING PIPELINE\n",
    "csv_keys = ['image_path', 'label_mask_path', 'label_json_path']\n",
    "\n",
    "Train_data_transform=Compose([\n",
    "    LoadData(csv_keys),  \n",
    "    ConvToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "Valid_data_transform=Compose([\n",
    "   LoadData(csv_keys),\n",
    "    ConvToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "Test_data_transform=Compose([\n",
    "   LoadData(['image_path']),\n",
    "   ConvToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, input_dataframe: pd.DataFrame, KeysOfInterest: List[str], data_transform:Compose): # TODO: add parameters if needed\n",
    "        self.koi = KeysOfInterest\n",
    "        self.input_dataframe = input_dataframe[self.koi]\n",
    "        self.data_transform=data_transform\n",
    "\n",
    "    def __getitem__(self, item: int):\n",
    "        sample = self.input_dataframe.iloc[item].to_dict()\n",
    "        transformed_sample = self.data_transform(sample)\n",
    "        return transformed_sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Initilize your datasets\n",
    "\n",
    "ds_train=Dataset(input_dataframe=train_df,\n",
    "                KeysOfInterest=csv_keys,\n",
    "                data_transform=Train_data_transform)\n",
    "\n",
    "ds_val=Dataset(input_dataframe=val_df,\n",
    "                KeysOfInterest=csv_keys,\n",
    "                data_transform=Valid_data_transform)\n",
    "\n",
    "ds_test=Dataset(input_dataframe=test_df,\n",
    "                KeysOfInterest=[\"image_path\"],\n",
    "                data_transform=Test_data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "dl_train = DataLoader(dataset=ds_train,batch_size= BATCH_SIZE,shuffle=True)\n",
    "dl_val = DataLoader(dataset=ds_val,batch_size= BATCH_SIZE ,num_workers=4 ,prefetch_factor=8,shuffle=True)\n",
    "dl_test = DataLoader(dataset=ds_test,batch_size= 1 ,num_workers=4 ,prefetch_factor=4,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Show samples from your data loaders\n",
    "\n",
    "def show_sample(image_tensor, mask_tensor=None):\n",
    "\n",
    "    if image_tensor.is_cuda:\n",
    "        image_tensor = image_tensor.cpu()\n",
    "    if mask_tensor is not None and mask_tensor.is_cuda:\n",
    "        mask_tensor = mask_tensor.cpu()\n",
    "    \n",
    "    # Convert the image tensor back to HWC format for plotting (CHW -> HWC)\n",
    "    image = image_tensor.permute(1, 2, 0).numpy()  # From CHW to HWC\n",
    "    image = (image * 255).astype(\"uint8\")  # Scale back to [0, 255] for visualization\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the mask (if available)\n",
    "    if mask_tensor is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mask_tensor.numpy(), cmap='gray')\n",
    "        plt.title(\"Mask\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Iterate through the dataloader and show a few samples\n",
    "def show_data_samples(dataloader, num_samples=5):\n",
    "    for i, (image_tensor, mask_tensor) in enumerate(dataloader):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        print(f\"Sample {i+1}:\")\n",
    "        show_sample(image_tensor[0], mask_tensor[0] if mask_tensor is not None else None)\n",
    "\n",
    "# Example usage to show samples from the training dataloader\n",
    "show_data_samples(dl_train, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Write the model you are going to use (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Write the loss function you are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Write the evaluation metrics you are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Write your own Training loop using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Plot losses and metrics graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Test your model and show some samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
