{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9589700,"sourceType":"datasetVersion","datasetId":5848669}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from collections import namedtuple","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:03.972882Z","iopub.execute_input":"2024-10-11T08:38:03.974161Z","iopub.status.idle":"2024-10-11T08:38:03.998314Z","shell.execute_reply.started":"2024-10-11T08:38:03.974113Z","shell.execute_reply":"2024-10-11T08:38:03.997181Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\n#--------------------------------------------------------------------------------\n# Definitions\n#--------------------------------------------------------------------------------\n\n# a label and all meta information\nLabel = namedtuple( 'Label' , [\n\n    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n                    # We use them to uniquely name a class\n\n    'id'          , # An integer ID that is associated with this label.\n                    # The IDs are used to represent the label in ground truth images\n                    # An ID of -1 means that this label does not have an ID and thus\n                    # is ignored when creating ground truth images (e.g. license plate).\n\n    'trainId'     , # An integer ID that overwrites the ID above, when creating ground truth\n                    # images for training.\n                    # For training, multiple labels might have the same ID. Then, these labels\n                    # are mapped to the same class in the ground truth images. For the inverse\n                    # mapping, we use the label that is defined first in the list below.\n                    # For example, mapping all void-type classes to the same ID in training,\n                    # might make sense for some approaches.\n\n    'category'    , # The name of the category that this label belongs to\n\n    'categoryId'  , # The ID of this category. Used to create ground truth images\n                    # on category level.\n\n    'hasInstances', # Whether this label distinguishes between single instances or not\n\n    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n                    # during evaluations or not\n\n    'color'       , # The color of this label\n    ] )\n\n\n#--------------------------------------------------------------------------------\n# A list of all labels\n#--------------------------------------------------------------------------------\n\n# Please adapt the train IDs as appropriate for you approach.\n# Note that you might want to ignore labels with ID 255 during training.\n# Make sure to provide your results using the original IDs and not the training IDs.\n# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n\nlabels = [\n    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n    Label(  'road'                 ,  7 ,        0 , 'ground'          , 1       , False        , False        , (128, 64,128) ),\n    Label(  'sidewalk'             ,  8 ,        1 , 'ground'          , 1       , False        , False        , (244, 35,232) ),\n    Label(  'parking'              ,  9 ,      255 , 'ground'          , 1       , False        , True         , (250,170,160) ),\n    Label(  'rail track'           , 10 ,      255 , 'ground'          , 1       , False        , True         , (230,150,140) ),\n    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n    Label(  'license plate'        , 34 ,       19 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n]","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:04.000449Z","iopub.execute_input":"2024-10-11T08:38:04.000868Z","iopub.status.idle":"2024-10-11T08:38:04.033027Z","shell.execute_reply.started":"2024-10-11T08:38:04.000827Z","shell.execute_reply":"2024-10-11T08:38:04.031551Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#TODO : Split the dataset into training and validation data\n#TODO : Save the split to csv file\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ntrain_images_folder = '/kaggle/input/cityscapes-segmentation/images/train'\ntrain_labels_folder = '/kaggle/input/cityscapes-segmentation/labels/train'\n\ndata = {\n    'city': [],\n    'image_path': [],\n    'label_mask_path': [],\n    'label_json_path': []\n}\n\nfor city in os.listdir(train_images_folder):\n    city_image_folder = os.path.join(train_images_folder, city)\n    city_label_folder = os.path.join(train_labels_folder, city)\n    \n    if os.path.isdir(city_image_folder):\n        for image_file in os.listdir(city_image_folder):\n            if image_file.endswith('_leftImg8bit.png'):\n                image_name_base = image_file.replace('_leftImg8bit.png', '')\n                label_mask_file = f\"{image_name_base}_gtFine_labelTrainIds.png\"\n                label_json_file = f\"{image_name_base}_gtFine_polygons.json\"\n                \n                data['city'].append(city)\n                data['image_path'].append(os.path.join(city_image_folder, image_file))\n                data['label_mask_path'].append(os.path.join(city_label_folder, label_mask_file))\n                data['label_json_path'].append(os.path.join(city_label_folder, label_json_file))\n\ndf = pd.DataFrame(data)\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=23, shuffle=True)\n\ntraining_csv_file_path = '/kaggle/working/cityscapes_training.csv'\nval_csv_file_path = '/kaggle/working/cityscapes_val.csv'\n\ntrain_df.to_csv(training_csv_file_path, index=False)\nval_df.to_csv(val_csv_file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:04.035184Z","iopub.execute_input":"2024-10-11T08:38:04.035581Z","iopub.status.idle":"2024-10-11T08:38:08.669560Z","shell.execute_reply.started":"2024-10-11T08:38:04.035526Z","shell.execute_reply":"2024-10-11T08:38:08.668140Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"test_images_folder = '/kaggle/input/cityscapes-segmentation/images/test'\n\ntest_data = {\n    'city': [],\n    'image_path': []\n}\n\nfor city in os.listdir(test_images_folder):\n    city_image_folder = os.path.join(test_images_folder, city)\n    \n    if os.path.isdir(city_image_folder):\n        for image_file in os.listdir(city_image_folder):\n            if image_file.endswith('_leftImg8bit.png'):\n                test_data['city'].append(city)\n                test_data['image_path'].append(os.path.join(city_image_folder, image_file))\n\ntest_df = pd.DataFrame(test_data)\n\ntest_csv_file_path = '/kaggle/working/cityscapes_test.csv'\n\ntest_df.to_csv(test_csv_file_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:08.672098Z","iopub.execute_input":"2024-10-11T08:38:08.672568Z","iopub.status.idle":"2024-10-11T08:38:09.137277Z","shell.execute_reply.started":"2024-10-11T08:38:08.672515Z","shell.execute_reply":"2024-10-11T08:38:09.135868Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#PRINT SAMPLE FROM CSV_FILE\ndf_train = pd.read_csv(\"/kaggle/working/cityscapes_training.csv\")\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:39:02.068445Z","iopub.execute_input":"2024-10-11T08:39:02.068976Z","iopub.status.idle":"2024-10-11T08:39:02.103162Z","shell.execute_reply.started":"2024-10-11T08:39:02.068929Z","shell.execute_reply":"2024-10-11T08:39:02.101834Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"         city                                         image_path  \\\n0      weimar  /kaggle/input/cityscapes-segmentation/images/t...   \n1     cologne  /kaggle/input/cityscapes-segmentation/images/t...   \n2    tubingen  /kaggle/input/cityscapes-segmentation/images/t...   \n3   stuttgart  /kaggle/input/cityscapes-segmentation/images/t...   \n4  strasbourg  /kaggle/input/cityscapes-segmentation/images/t...   \n\n                                     label_mask_path  \\\n0  /kaggle/input/cityscapes-segmentation/labels/t...   \n1  /kaggle/input/cityscapes-segmentation/labels/t...   \n2  /kaggle/input/cityscapes-segmentation/labels/t...   \n3  /kaggle/input/cityscapes-segmentation/labels/t...   \n4  /kaggle/input/cityscapes-segmentation/labels/t...   \n\n                                     label_json_path  \n0  /kaggle/input/cityscapes-segmentation/labels/t...  \n1  /kaggle/input/cityscapes-segmentation/labels/t...  \n2  /kaggle/input/cityscapes-segmentation/labels/t...  \n3  /kaggle/input/cityscapes-segmentation/labels/t...  \n4  /kaggle/input/cityscapes-segmentation/labels/t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>image_path</th>\n      <th>label_mask_path</th>\n      <th>label_json_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>weimar</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cologne</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tubingen</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>stuttgart</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>strasbourg</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n      <td>/kaggle/input/cityscapes-segmentation/labels/t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/working/cityscapes_test.csv\")\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:39:04.424962Z","iopub.execute_input":"2024-10-11T08:39:04.425869Z","iopub.status.idle":"2024-10-11T08:39:04.442298Z","shell.execute_reply.started":"2024-10-11T08:39:04.425826Z","shell.execute_reply":"2024-10-11T08:39:04.440749Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"         city                                         image_path\n0  dusseldorf  /kaggle/input/cityscapes-segmentation/images/t...\n1  dusseldorf  /kaggle/input/cityscapes-segmentation/images/t...\n2  dusseldorf  /kaggle/input/cityscapes-segmentation/images/t...\n3  dusseldorf  /kaggle/input/cityscapes-segmentation/images/t...\n4  dusseldorf  /kaggle/input/cityscapes-segmentation/images/t...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dusseldorf</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dusseldorf</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dusseldorf</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dusseldorf</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dusseldorf</td>\n      <td>/kaggle/input/cityscapes-segmentation/images/t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#TODO: write your own data analysis techniques\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:09.200402Z","iopub.execute_input":"2024-10-11T08:38:09.200882Z","iopub.status.idle":"2024-10-11T08:38:09.206689Z","shell.execute_reply.started":"2024-10-11T08:38:09.200827Z","shell.execute_reply":"2024-10-11T08:38:09.205346Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Example for the desired interface \n\n#class LoadImage():\n#    def __init__(self,keys):\n#        self.keys=keys\n#    def __call__(self,sample):\n#        for key in self.keys:\n#            sample[key]=cv2.loadImage()\n#        return sample","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:09.209077Z","iopub.execute_input":"2024-10-11T08:38:09.209577Z","iopub.status.idle":"2024-10-11T08:38:09.306092Z","shell.execute_reply.started":"2024-10-11T08:38:09.209526Z","shell.execute_reply":"2024-10-11T08:38:09.304650Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#TODO : TRAIN DATA PREPROCESSING PIPELINE\n#Train_data_transform=Compose([\n#    LoadImage( keys= ['image','mask'] ),\n    \n    #Write your own data transforms and augmentations\n\n#])\n\n\n#TODO : VALIDATION DATA PREPROCESSING PIPELINE\n\n\n#Valid_data_transform=Compose([\n#    LoadImage(['image','mask']),\n    \n    #Write your own data transforms and augmentations\n\n#])\n\n#TODO : TEST DATA PREPROCESSING PIPELINE\n\n\n#Test_data_transform=Compose([\n#    LoadImage(['image','mask']),\n    \n    #Write your own data transforms and augmentations\n\n#])","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:09.311500Z","iopub.execute_input":"2024-10-11T08:38:09.312047Z","iopub.status.idle":"2024-10-11T08:38:09.319275Z","shell.execute_reply.started":"2024-10-11T08:38:09.311993Z","shell.execute_reply":"2024-10-11T08:38:09.317882Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import re\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nfrom typing import List\nfrom torchvision.transforms import Compose\n\n\nclass Dataset(Dataset):\n    def __init__(self, input_dataframe: pd.DataFrame, KeysOfInterest: List[str], data_transform:Compose): # TODO: add parameters if needed\n        self.koi = KeysOfInterest\n        self.input_dataframe = input_dataframe[self.koi]\n        self.data_transform=data_transform\n\n    def __getitem__(self, item: int):\n        pass\n        #TODO : write this function\n        \n    def __len__(self):\n        return len(self.input_dataframe)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:09.321158Z","iopub.execute_input":"2024-10-11T08:38:09.321588Z","iopub.status.idle":"2024-10-11T08:38:14.219819Z","shell.execute_reply.started":"2024-10-11T08:38:09.321547Z","shell.execute_reply":"2024-10-11T08:38:14.218576Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#TODO : Initilize your datasets\n\n#ds_train=Dataset(input_dataframe=csv_train,\n#                 root_dir=\"\",\n#                 KeysOfInterest=[\"\",\"\"],\n#                 data_transform=train_data_transform)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.221474Z","iopub.execute_input":"2024-10-11T08:38:14.222103Z","iopub.status.idle":"2024-10-11T08:38:14.227862Z","shell.execute_reply.started":"2024-10-11T08:38:14.222061Z","shell.execute_reply":"2024-10-11T08:38:14.226341Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#dl_train=DataLoader(dataset=ds_train,batch_size= 2 ,num_workers=8 ,prefetch_factor=8,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.232549Z","iopub.execute_input":"2024-10-11T08:38:14.233580Z","iopub.status.idle":"2024-10-11T08:38:14.242396Z","shell.execute_reply.started":"2024-10-11T08:38:14.233536Z","shell.execute_reply":"2024-10-11T08:38:14.241285Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#TODO : Show samples from your data loaders","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.244192Z","iopub.execute_input":"2024-10-11T08:38:14.244750Z","iopub.status.idle":"2024-10-11T08:38:14.253491Z","shell.execute_reply.started":"2024-10-11T08:38:14.244697Z","shell.execute_reply":"2024-10-11T08:38:14.252183Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#TODO : Write the model you are going to use (Pytorch)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.255435Z","iopub.execute_input":"2024-10-11T08:38:14.255983Z","iopub.status.idle":"2024-10-11T08:38:14.263285Z","shell.execute_reply.started":"2024-10-11T08:38:14.255934Z","shell.execute_reply":"2024-10-11T08:38:14.262275Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#TODO : Write the loss function you are going to use","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.264832Z","iopub.execute_input":"2024-10-11T08:38:14.265837Z","iopub.status.idle":"2024-10-11T08:38:14.351424Z","shell.execute_reply.started":"2024-10-11T08:38:14.265728Z","shell.execute_reply":"2024-10-11T08:38:14.350173Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#TODO : Write the evaluation metrics you are going to use","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.353109Z","iopub.execute_input":"2024-10-11T08:38:14.353765Z","iopub.status.idle":"2024-10-11T08:38:14.362837Z","shell.execute_reply.started":"2024-10-11T08:38:14.353725Z","shell.execute_reply":"2024-10-11T08:38:14.361347Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#TODO : Write your own Training loop using pytorch","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.364432Z","iopub.execute_input":"2024-10-11T08:38:14.364859Z","iopub.status.idle":"2024-10-11T08:38:14.374500Z","shell.execute_reply.started":"2024-10-11T08:38:14.364810Z","shell.execute_reply":"2024-10-11T08:38:14.373260Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#TODO : Plot losses and metrics graphs","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.376775Z","iopub.execute_input":"2024-10-11T08:38:14.377918Z","iopub.status.idle":"2024-10-11T08:38:14.384958Z","shell.execute_reply.started":"2024-10-11T08:38:14.377855Z","shell.execute_reply":"2024-10-11T08:38:14.383854Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#TODO : Test your model and show some samples","metadata":{"execution":{"iopub.status.busy":"2024-10-11T08:38:14.386219Z","iopub.execute_input":"2024-10-11T08:38:14.386565Z","iopub.status.idle":"2024-10-11T08:38:14.395539Z","shell.execute_reply.started":"2024-10-11T08:38:14.386514Z","shell.execute_reply":"2024-10-11T08:38:14.394411Z"},"trusted":true},"execution_count":19,"outputs":[]}]}